{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-21T17:14:58.020319Z",
     "start_time": "2026-01-21T17:14:58.010752Z"
    }
   },
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from llms import model, ollama_model\n",
    "from prompts import query_refinement, image_query_extraction\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:15:00.262636Z",
     "start_time": "2026-01-21T17:15:00.257371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def refine(query):\n",
    "    prompt = ChatPromptTemplate.from_template(query_refinement)\n",
    "    chain = prompt | model\n",
    "    try:\n",
    "        answer = chain.invoke({\"query\": query})\n",
    "        return answer.content\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to parse: {str(e)}\", \"raw_query\": query}"
   ],
   "id": "3cd99047b86cca90",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:15:04.799163Z",
     "start_time": "2026-01-21T17:15:02.139612Z"
    }
   },
   "cell_type": "code",
   "source": "print(refine(\"cheap headphones\"))",
   "id": "c9239fd490b6698d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"semantic_query\": \"headphones\", \"filters\": { \"max_price\": 50, \"category\": \"headphones\" }, \"financial_priority\": \"low_total_price\"}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:15:28.916668Z",
     "start_time": "2026-01-21T17:15:28.904934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "def describe_image(image_path: str):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": image_query_extraction},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = model.invoke([message])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"Error describing image: {str(e)}\""
   ],
   "id": "78bd38636e70f5b3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(describe_image(\"camera.jpg\"))",
   "id": "681d000f129f833",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:16:30.100629Z",
     "start_time": "2026-01-21T17:16:27.575397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Hybrid_Search import HybridSearcher\n",
    "hybrid_searcher = HybridSearcher(collection_name=\"products\")\n",
    "print(hybrid_searcher.search(text=\"leather jacket for men\"))"
   ],
   "id": "5af2be88b40c4694",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find tokenizer_config.json in C:\\Users\\GIGABYTE\\AppData\\Local\\Temp\\fastembed_cache\\models--qdrant--all-MiniLM-L6-v2-onnx\\snapshots\\5f1b8cd78bc4fb444dd171e59b18f3a3af89a079",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mHybrid_Search\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m HybridSearcher\n\u001B[32m      2\u001B[39m hybrid_searcher = HybridSearcher(collection_name=\u001B[33m\"\u001B[39m\u001B[33mproducts\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mhybrid_searcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mleather jacket for men\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\App\\Hybrid_Search.py:13\u001B[39m, in \u001B[36mHybridSearcher.search\u001B[39m\u001B[34m(self, text)\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msearch\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     search_result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mqdrant_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mquery_points\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFusionQuery\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfusion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFusion\u001B[49m\u001B[43m.\u001B[49m\u001B[43mRRF\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprefetch\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPrefetch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m                \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mDocument\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mDENSE_MODEL\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m                \u001B[49m\u001B[43musing\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtext-dense\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPrefetch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[43m                \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mDocument\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mSPARSE_MODEL\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     25\u001B[39m \u001B[43m                \u001B[49m\u001B[43musing\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtext-sparse\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_filter\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlimit\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m.points\n\u001B[32m     31\u001B[39m     metadata = [point.payload \u001B[38;5;28;01mfor\u001B[39;00m point \u001B[38;5;129;01min\u001B[39;00m search_result]\n\u001B[32m     32\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m metadata\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_client.py:403\u001B[39m, in \u001B[36mQdrantClient.query_points\u001B[39m\u001B[34m(self, collection_name, query, using, prefetch, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, lookup_from, consistency, shard_key_selector, timeout, **kwargs)\u001B[39m\n\u001B[32m    391\u001B[39m query = (\n\u001B[32m    392\u001B[39m     \u001B[38;5;28mnext\u001B[39m(\n\u001B[32m    393\u001B[39m         \u001B[38;5;28miter\u001B[39m(\n\u001B[32m   (...)\u001B[39m\u001B[32m    400\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    401\u001B[39m )\n\u001B[32m    402\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(prefetch, \u001B[38;5;28mlist\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m403\u001B[39m     prefetch = \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embed_models\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    405\u001B[39m \u001B[43m            \u001B[49m\u001B[43mprefetch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlocal_inference_batch_size\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    407\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    408\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    409\u001B[39m     prefetch = (\n\u001B[32m    410\u001B[39m         \u001B[38;5;28mnext\u001B[39m(\n\u001B[32m    411\u001B[39m             \u001B[38;5;28miter\u001B[39m(\n\u001B[32m   (...)\u001B[39m\u001B[32m    420\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    421\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_fastembed.py:885\u001B[39m, in \u001B[36mQdrantFastembedMixin._embed_models\u001B[39m\u001B[34m(self, raw_models, is_query, batch_size)\u001B[39m\n\u001B[32m    879\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_embed_models\u001B[39m(\n\u001B[32m    880\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    881\u001B[39m     raw_models: BaseModel | Iterable[BaseModel],\n\u001B[32m    882\u001B[39m     is_query: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    883\u001B[39m     batch_size: \u001B[38;5;28mint\u001B[39m | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    884\u001B[39m ) -> Iterable[BaseModel]:\n\u001B[32m--> \u001B[39m\u001B[32m885\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._model_embedder.embed_models(\n\u001B[32m    886\u001B[39m         raw_models=raw_models,\n\u001B[32m    887\u001B[39m         is_query=is_query,\n\u001B[32m    888\u001B[39m         batch_size=batch_size \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.DEFAULT_BATCH_SIZE,\n\u001B[32m    889\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\model_embedder.py:110\u001B[39m, in \u001B[36mModelEmbedder.embed_models\u001B[39m\u001B[34m(self, raw_models, is_query, batch_size)\u001B[39m\n\u001B[32m    108\u001B[39m     raw_models = [raw_models]\n\u001B[32m    109\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m raw_models_batch \u001B[38;5;129;01min\u001B[39;00m iter_batch(raw_models, batch_size):\n\u001B[32m--> \u001B[39m\u001B[32m110\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m.embed_models_batch(\n\u001B[32m    111\u001B[39m         raw_models_batch, is_query, inference_batch_size=batch_size\n\u001B[32m    112\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\model_embedder.py:197\u001B[39m, in \u001B[36mModelEmbedder.embed_models_batch\u001B[39m\u001B[34m(self, raw_models, is_query, inference_batch_size)\u001B[39m\n\u001B[32m    195\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m raw_models\n\u001B[32m    196\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m (\n\u001B[32m    198\u001B[39m         \u001B[38;5;28mself\u001B[39m._process_model(\n\u001B[32m    199\u001B[39m             raw_model,\n\u001B[32m    200\u001B[39m             is_query=is_query,\n\u001B[32m    201\u001B[39m             accumulating=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    202\u001B[39m             inference_batch_size=inference_batch_size,\n\u001B[32m    203\u001B[39m         )\n\u001B[32m    204\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m raw_model \u001B[38;5;129;01min\u001B[39;00m raw_models\n\u001B[32m    205\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\model_embedder.py:198\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    195\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m raw_models\n\u001B[32m    196\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    197\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m (\n\u001B[32m--> \u001B[39m\u001B[32m198\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_process_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    199\u001B[39m \u001B[43m            \u001B[49m\u001B[43mraw_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    200\u001B[39m \u001B[43m            \u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    201\u001B[39m \u001B[43m            \u001B[49m\u001B[43maccumulating\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    202\u001B[39m \u001B[43m            \u001B[49m\u001B[43minference_batch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43minference_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    203\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    204\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m raw_model \u001B[38;5;129;01min\u001B[39;00m raw_models\n\u001B[32m    205\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\model_embedder.py:283\u001B[39m, in \u001B[36mModelEmbedder._process_model\u001B[39m\u001B[34m(self, model, paths, is_query, accumulating, inference_batch_size)\u001B[39m\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m accumulating:\n\u001B[32m    279\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[32m    280\u001B[39m         inference_batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    281\u001B[39m     ), \u001B[33m\"\u001B[39m\u001B[33minference_batch_size should be passed for inference\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    282\u001B[39m     embeddings = [\n\u001B[32m--> \u001B[39m\u001B[32m283\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_drain_accumulator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minference_batch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43minference_batch_size\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    286\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m current_model\n\u001B[32m    287\u001B[39m     ]\n\u001B[32m    288\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m was_list:\n\u001B[32m    289\u001B[39m         \u001B[38;5;28msetattr\u001B[39m(item, path.current, embeddings)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\model_embedder.py:365\u001B[39m, in \u001B[36mModelEmbedder._drain_accumulator\u001B[39m\u001B[34m(self, data, is_query, inference_batch_size)\u001B[39m\n\u001B[32m    362\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m data  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m    364\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._embed_storage \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._embed_storage.get(data.model, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m365\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embed_accumulator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minference_batch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43minference_batch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._next_embed(data.model)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\model_embedder.py:448\u001B[39m, in \u001B[36mModelEmbedder._embed_accumulator\u001B[39m\u001B[34m(self, is_query, inference_batch_size)\u001B[39m\n\u001B[32m    445\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m is not among supported models\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    447\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m model, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._batch_accumulator.items():\n\u001B[32m--> \u001B[39m\u001B[32m448\u001B[39m     \u001B[38;5;28mself\u001B[39m._embed_storage[model] = \u001B[43membed\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    449\u001B[39m \u001B[43m        \u001B[49m\u001B[43mobjects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43minference_batch_size\u001B[49m\n\u001B[32m    450\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._batch_accumulator.clear()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\model_embedder.py:411\u001B[39m, in \u001B[36mModelEmbedder._embed_accumulator.<locals>.embed\u001B[39m\u001B[34m(objects, model_name, batch_size)\u001B[39m\n\u001B[32m    406\u001B[39m embeddings = []\n\u001B[32m    407\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, (options, is_text) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(unique_options, unique_options_is_text)):\n\u001B[32m    408\u001B[39m     embeddings.extend(\n\u001B[32m    409\u001B[39m         [\n\u001B[32m    410\u001B[39m             embedding\n\u001B[32m--> \u001B[39m\u001B[32m411\u001B[39m             \u001B[38;5;28;01mfor\u001B[39;00m embedding \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43membedder\u001B[49m\u001B[43m.\u001B[49m\u001B[43membed\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    412\u001B[39m \u001B[43m                \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    413\u001B[39m \u001B[43m                \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatches\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    414\u001B[39m \u001B[43m                \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatches\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    415\u001B[39m \u001B[43m                \u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    416\u001B[39m \u001B[43m                \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    417\u001B[39m \u001B[43m                \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    418\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    419\u001B[39m         ]\n\u001B[32m    420\u001B[39m     )\n\u001B[32m    422\u001B[39m iter_embeddings = \u001B[38;5;28miter\u001B[39m(embeddings)\n\u001B[32m    423\u001B[39m ordered_embeddings: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[NumericVector]] = [[]] * \u001B[38;5;28mlen\u001B[39m(objects)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\embedder.py:237\u001B[39m, in \u001B[36mEmbedder.embed\u001B[39m\u001B[34m(self, model_name, texts, images, options, is_query, batch_size)\u001B[39m\n\u001B[32m    235\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m texts \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    236\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m FastEmbedMisc.is_supported_text_model(model_name):\n\u001B[32m--> \u001B[39m\u001B[32m237\u001B[39m         embeddings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embed_dense_text\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    238\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\n\u001B[32m    239\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    240\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m FastEmbedMisc.is_supported_sparse_model(model_name):\n\u001B[32m    241\u001B[39m         embeddings = \u001B[38;5;28mself\u001B[39m._embed_sparse_text(\n\u001B[32m    242\u001B[39m             texts, model_name, options, is_query, batch_size\n\u001B[32m    243\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\embedder.py:277\u001B[39m, in \u001B[36mEmbedder._embed_dense_text\u001B[39m\u001B[34m(self, texts, model_name, options, is_query, batch_size)\u001B[39m\n\u001B[32m    269\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_embed_dense_text\u001B[39m(\n\u001B[32m    270\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    271\u001B[39m     texts: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m    275\u001B[39m     batch_size: \u001B[38;5;28mint\u001B[39m,\n\u001B[32m    276\u001B[39m ) -> \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mfloat\u001B[39m]]:\n\u001B[32m--> \u001B[39m\u001B[32m277\u001B[39m     embedding_model_inst = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_or_init_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    279\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_query:\n\u001B[32m    280\u001B[39m         embeddings = [\n\u001B[32m    281\u001B[39m             embedding.tolist()\n\u001B[32m    282\u001B[39m             \u001B[38;5;28;01mfor\u001B[39;00m embedding \u001B[38;5;129;01min\u001B[39;00m embedding_model_inst.embed(documents=texts, batch_size=batch_size)\n\u001B[32m    283\u001B[39m         ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\qdrant_client\\embed\\embedder.py:75\u001B[39m, in \u001B[36mEmbedder.get_or_init_model\u001B[39m\u001B[34m(self, model_name, cache_dir, threads, providers, cuda, device_ids, deprecated, **kwargs)\u001B[39m\n\u001B[32m     70\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (deprecated \u001B[38;5;129;01mand\u001B[39;00m instance.deprecated) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m     71\u001B[39m         \u001B[38;5;129;01mnot\u001B[39;00m deprecated \u001B[38;5;129;01mand\u001B[39;00m instance.options == options\n\u001B[32m     72\u001B[39m     ):\n\u001B[32m     73\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m instance.model\n\u001B[32m---> \u001B[39m\u001B[32m75\u001B[39m model = \u001B[43mTextEmbedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     76\u001B[39m model_instance: ModelInstance[TextEmbedding] = ModelInstance(\n\u001B[32m     77\u001B[39m     model=model, options=options, deprecated=deprecated\n\u001B[32m     78\u001B[39m )\n\u001B[32m     79\u001B[39m \u001B[38;5;28mself\u001B[39m.embedding_models[model_name].append(model_instance)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\fastembed\\text\\text_embedding.py:114\u001B[39m, in \u001B[36mTextEmbedding.__init__\u001B[39m\u001B[34m(self, model_name, cache_dir, threads, providers, cuda, device_ids, lazy_load, **kwargs)\u001B[39m\n\u001B[32m    112\u001B[39m     supported_models = EMBEDDING_MODEL_TYPE._list_supported_models()\n\u001B[32m    113\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(model_name.lower() == model.model.lower() \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m supported_models):\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m         \u001B[38;5;28mself\u001B[39m.model = \u001B[43mEMBEDDING_MODEL_TYPE\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    115\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    116\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    117\u001B[39m \u001B[43m            \u001B[49m\u001B[43mthreads\u001B[49m\u001B[43m=\u001B[49m\u001B[43mthreads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[43m            \u001B[49m\u001B[43mproviders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproviders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    119\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    120\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdevice_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    121\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlazy_load\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlazy_load\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    124\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    127\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m is not supported in TextEmbedding. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    128\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mPlease check the supported models using `TextEmbedding.list_supported_models()`\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    129\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\fastembed\\text\\onnx_embedding.py:259\u001B[39m, in \u001B[36mOnnxTextEmbedding.__init__\u001B[39m\u001B[34m(self, model_name, cache_dir, threads, providers, cuda, device_ids, lazy_load, device_id, specific_model_path, **kwargs)\u001B[39m\n\u001B[32m    251\u001B[39m \u001B[38;5;28mself\u001B[39m._model_dir = \u001B[38;5;28mself\u001B[39m.download_model(\n\u001B[32m    252\u001B[39m     \u001B[38;5;28mself\u001B[39m.model_description,\n\u001B[32m    253\u001B[39m     \u001B[38;5;28mself\u001B[39m.cache_dir,\n\u001B[32m    254\u001B[39m     local_files_only=\u001B[38;5;28mself\u001B[39m._local_files_only,\n\u001B[32m    255\u001B[39m     specific_model_path=\u001B[38;5;28mself\u001B[39m._specific_model_path,\n\u001B[32m    256\u001B[39m )\n\u001B[32m    258\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.lazy_load:\n\u001B[32m--> \u001B[39m\u001B[32m259\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mload_onnx_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\fastembed\\text\\onnx_embedding.py:324\u001B[39m, in \u001B[36mOnnxTextEmbedding.load_onnx_model\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    323\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_onnx_model\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m324\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_load_onnx_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    325\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_model_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    326\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel_description\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    327\u001B[39m \u001B[43m        \u001B[49m\u001B[43mthreads\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mthreads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    328\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproviders\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mproviders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    329\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    330\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice_id\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdevice_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_session_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_extra_session_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    332\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\fastembed\\text\\onnx_text_model.py:68\u001B[39m, in \u001B[36mOnnxTextModel._load_onnx_model\u001B[39m\u001B[34m(self, model_dir, model_file, threads, providers, cuda, device_id, extra_session_options)\u001B[39m\n\u001B[32m     49\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_load_onnx_model\u001B[39m(\n\u001B[32m     50\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m     51\u001B[39m     model_dir: Path,\n\u001B[32m   (...)\u001B[39m\u001B[32m     57\u001B[39m     extra_session_options: Optional[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m     58\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     59\u001B[39m     \u001B[38;5;28msuper\u001B[39m()._load_onnx_model(\n\u001B[32m     60\u001B[39m         model_dir=model_dir,\n\u001B[32m     61\u001B[39m         model_file=model_file,\n\u001B[32m   (...)\u001B[39m\u001B[32m     66\u001B[39m         extra_session_options=extra_session_options,\n\u001B[32m     67\u001B[39m     )\n\u001B[32m---> \u001B[39m\u001B[32m68\u001B[39m     \u001B[38;5;28mself\u001B[39m.tokenizer, \u001B[38;5;28mself\u001B[39m.special_token_to_id = \u001B[43mload_tokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_dir\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\VectorsHackthon\\.venv\\Lib\\site-packages\\fastembed\\common\\preprocessor_utils.py:32\u001B[39m, in \u001B[36mload_tokenizer\u001B[39m\u001B[34m(model_dir)\u001B[39m\n\u001B[32m     30\u001B[39m tokenizer_config_path = model_dir / \u001B[33m\"\u001B[39m\u001B[33mtokenizer_config.json\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tokenizer_config_path.exists():\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCould not find tokenizer_config.json in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mstr\u001B[39m(config_path)) \u001B[38;5;28;01mas\u001B[39;00m config_file:\n\u001B[32m     35\u001B[39m     config = json.load(config_file)\n",
      "\u001B[31mValueError\u001B[39m: Could not find tokenizer_config.json in C:\\Users\\GIGABYTE\\AppData\\Local\\Temp\\fastembed_cache\\models--qdrant--all-MiniLM-L6-v2-onnx\\snapshots\\5f1b8cd78bc4fb444dd171e59b18f3a3af89a079"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
